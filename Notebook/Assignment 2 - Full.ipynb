{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predictive Models\n",
    "# Cory Lowe\n",
    "# Assignment 2 - Full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "Task: \n",
    "\n",
    "1)\tPreprocess and EDA data as needed. Don’t just do EDA, discuss what it tell you about the data and how it informs you in different decisions you make about the below models. \n",
    "\n",
    "2)\tRun and tune at least the below methods. You will create several different tuning of each. Like KNN-3 AND KNN-5, using different distance measurements, Or SVM with kernels, cost functions and gammas, OR Random Forest with different \"trys\". Report your best tuned model for each. Don’t forget to CV. If you just did three tunings per model, you would be trying 36 different models on this dataset. That is probably a minimum. Grid search is your friend, but also your enemy if you ask it to search through too much. This is a great way to learn how to balance the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pwd\n",
    "path = \"C:/Users/corylowe/OneDrive/Rockhurst/Predictive Models/Assignment 2 - Full\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Census Data Has Been Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>workClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educationNum</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalGain</th>\n",
       "      <th>capitalLoss</th>\n",
       "      <th>hoursPerWeek</th>\n",
       "      <th>nativeCountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Jamaica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income  age          workClass  fnlwgt   education  educationNum  \\\n",
       "0   <=50K   39          State-gov   77516   Bachelors            13   \n",
       "1   <=50K   50   Self-emp-not-inc   83311   Bachelors            13   \n",
       "2   <=50K   38            Private  215646     HS-grad             9   \n",
       "3   <=50K   53            Private  234721        11th             7   \n",
       "4   <=50K   28            Private  338409   Bachelors            13   \n",
       "5   <=50K   37            Private  284582     Masters            14   \n",
       "6   <=50K   49            Private  160187         9th             5   \n",
       "7    >50K   52   Self-emp-not-inc  209642     HS-grad             9   \n",
       "8    >50K   31            Private   45781     Masters            14   \n",
       "9    >50K   42            Private  159449   Bachelors            13   \n",
       "\n",
       "            maritalStatus          occupation    relationship    race  \\\n",
       "0           Never-married        Adm-clerical   Not-in-family   White   \n",
       "1      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3      Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4      Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "5      Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "6   Married-spouse-absent       Other-service   Not-in-family   Black   \n",
       "7      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "8           Never-married      Prof-specialty   Not-in-family   White   \n",
       "9      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "\n",
       "       sex  capitalGain  capitalLoss  hoursPerWeek   nativeCountry  \n",
       "0     Male         2174            0            40   United-States  \n",
       "1     Male            0            0            13   United-States  \n",
       "2     Male            0            0            40   United-States  \n",
       "3     Male            0            0            40   United-States  \n",
       "4   Female            0            0            40            Cuba  \n",
       "5   Female            0            0            40   United-States  \n",
       "6   Female            0            0            16         Jamaica  \n",
       "7     Male            0            0            45   United-States  \n",
       "8   Female        14084            0            50   United-States  \n",
       "9     Male         5178            0            40   United-States  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(path)\n",
    "\n",
    "Income=pd.read_csv(path + \"/data/Census Income.csv\", encoding = \"ISO-8859-1\")\n",
    "Income\n",
    "Income.shape\n",
    "Income.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Source: https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "#### I copied the data into a CSV and moved the income (predictor variable) to the left hand side, which will make writing the code easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# I Am Dropping the Weighting Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>workClass</th>\n",
       "      <th>education</th>\n",
       "      <th>educationNum</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalGain</th>\n",
       "      <th>capitalLoss</th>\n",
       "      <th>hoursPerWeek</th>\n",
       "      <th>nativeCountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Jamaica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income  age          workClass   education  educationNum  \\\n",
       "0   <=50K   39          State-gov   Bachelors            13   \n",
       "1   <=50K   50   Self-emp-not-inc   Bachelors            13   \n",
       "2   <=50K   38            Private     HS-grad             9   \n",
       "3   <=50K   53            Private        11th             7   \n",
       "4   <=50K   28            Private   Bachelors            13   \n",
       "5   <=50K   37            Private     Masters            14   \n",
       "6   <=50K   49            Private         9th             5   \n",
       "7    >50K   52   Self-emp-not-inc     HS-grad             9   \n",
       "8    >50K   31            Private     Masters            14   \n",
       "9    >50K   42            Private   Bachelors            13   \n",
       "\n",
       "            maritalStatus          occupation    relationship    race  \\\n",
       "0           Never-married        Adm-clerical   Not-in-family   White   \n",
       "1      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3      Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4      Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "5      Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "6   Married-spouse-absent       Other-service   Not-in-family   Black   \n",
       "7      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "8           Never-married      Prof-specialty   Not-in-family   White   \n",
       "9      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "\n",
       "       sex  capitalGain  capitalLoss  hoursPerWeek   nativeCountry  \n",
       "0     Male         2174            0            40   United-States  \n",
       "1     Male            0            0            13   United-States  \n",
       "2     Male            0            0            40   United-States  \n",
       "3     Male            0            0            40   United-States  \n",
       "4   Female            0            0            40            Cuba  \n",
       "5   Female            0            0            40   United-States  \n",
       "6   Female            0            0            16         Jamaica  \n",
       "7     Male            0            0            45   United-States  \n",
       "8   Female        14084            0            50   United-States  \n",
       "9     Male         5178            0            40   United-States  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Income[\"fnlwgt\"]\n",
    "Income.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The census bureau weights classes of individuals based on how well they are represented in the survey. I removed these weights as we might not have access to this data on future cases. I don't want to create a situation where the models can't be run becasuse independent variables are missing. In a real scenario, I would investiage to determine if we would have this data.\n",
    "#### Source: https://www.census.gov/programs-surveys/sipp/methodology/weighting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# I created excel pivot tables of each variable and found the following variables have missing values.\n",
    "-  Working Class\n",
    "-  Occupation\n",
    "-  Native Country\n",
    "\n",
    "#### Therefore, I am replacing these missing values with the most common value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# I Am Dropping the Education Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Income[\"education\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The education and education number are 2 ways of measuring the same thing.\n",
    "#### Only one variable should be in the model to prevent multi-colinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Plots showing N/A values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working class showing N/A values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAFWCAYAAACCfFH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERHkkNERHQkOURERMf/B2GjtLinBaBLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dba2b4e3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "groupby = Income.groupby(\"workClass\")\n",
    "groupByEDA=groupby[\"workClass\"].aggregate(len)\n",
    "plt.figure()\n",
    "groupByEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation class showing N/A values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAFfCAYAAACobXB7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKIEgCII+JpRAEARBHxNKIAiCoI/5/5XIfYZluTPKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dba0ce6278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "groupby = Income.groupby(\"occupation\")\n",
    "groupByEDA=groupby[\"occupation\"].aggregate(len)\n",
    "plt.figure()\n",
    "groupByEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Native country showing N/A values\n",
    "#### Hint - They are in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAGSCAYAAAAIBQ1WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4/T9P/l3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dba0a21080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "groupby = Income.groupby(\"nativeCountry\")\n",
    "groupByEDA=groupby[\"nativeCountry\"].aggregate(len)\n",
    "plt.figure()\n",
    "groupByEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing working class N/As with most popular category (private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Income['workClass'] = Income['workClass'].str.replace('NA', 'Private')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Bar Plot of Working Class With N/As Replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAFWCAYAAACCfFH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nySEiImqSHCIioibJISIiapIcIiKi5v8DOWc5A0QzFfsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dba2c42780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "groupby = Income.groupby(\"workClass\")\n",
    "groupByEDA=groupby[\"workClass\"].aggregate(len)\n",
    "plt.figure()\n",
    "groupByEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Replacing professional N/As with most popular category (private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Income['occupation'] = Income['occupation'].str.replace('NA', ' Prof-specialty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAFfCAYAAACobXB7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dba3328048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "groupby = Income.groupby(\"occupation\")\n",
    "groupByEDA=groupby[\"occupation\"].aggregate(len)\n",
    "plt.figure()\n",
    "groupByEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Replacing country N/As with most popular category (United States)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Income['nativeCountry'] = Income['nativeCountry'].str.replace('NA', 'United-States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAGSCAYAAAAIBQ1WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIrokOURERJckh4iI6PJHOQMt10cB6ukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dba33d6ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "groupby = Income.groupby(\"nativeCountry\")\n",
    "groupByEDA=groupby[\"nativeCountry\"].aggregate(len)\n",
    "plt.figure()\n",
    "groupByEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Categorical Variables Into Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Name_Dummy=pd.DataFrame(pd.get_dummies(Income['workClass']))\n",
    "Name_Dummy.columns\n",
    "Income[' Federal-gov']=Name_Dummy[' Federal-gov']\n",
    "Income[' Local-gov']=Name_Dummy[' Local-gov']\n",
    "Income[' Never-worked']=Name_Dummy[' Never-worked']\n",
    "Income[' Private']=Name_Dummy[' Private']\n",
    "Income[' Self-emp-inc']=Name_Dummy[' Self-emp-inc']\n",
    "Income[' Self-emp-not-inc']=Name_Dummy[' Self-emp-not-inc']\n",
    "Income[' State-gov']=Name_Dummy[' State-gov']\n",
    "Income[' Without-pay']=Name_Dummy[' Without-pay']                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Name_Dummy=pd.DataFrame(pd.get_dummies(Income['maritalStatus']))\n",
    "Name_Dummy.columns\n",
    "Income[' Divorced']=Name_Dummy[' Divorced']\n",
    "Income[' Married-AF-spouse']=Name_Dummy[' Married-AF-spouse']\n",
    "Income[' Married-civ-spouse']=Name_Dummy[' Married-civ-spouse']\n",
    "Income[' Married-spouse-absent']=Name_Dummy[' Married-spouse-absent']\n",
    "Income[' Never-married']=Name_Dummy[' Never-married']\n",
    "Income[' Separated']=Name_Dummy[' Separated']\n",
    "Income[' Widowed']=Name_Dummy[' Widowed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Name_Dummy=pd.DataFrame(pd.get_dummies(Income['occupation']))\n",
    "Name_Dummy.columns\n",
    "Income[' Exec-managerial']=Name_Dummy[' Exec-managerial']\n",
    "Income[' Farming-fishing']=Name_Dummy[' Farming-fishing']\n",
    "Income[' Handlers-cleaners']=Name_Dummy[' Handlers-cleaners']\n",
    "Income[' Machine-op-inspct']=Name_Dummy[' Machine-op-inspct']\n",
    "Income[' Other-service']=Name_Dummy[' Other-service']\n",
    "Income[' Prof-specialty']=Name_Dummy[' Prof-specialty']\n",
    "Income[' Protective-serv']=Name_Dummy[' Protective-serv']\n",
    "Income[' Sales']=Name_Dummy[' Sales']\n",
    "Income[' Tech-support']=Name_Dummy[' Tech-support']\n",
    "Income[' Transport-moving']=Name_Dummy[' Transport-moving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Name_Dummy=pd.DataFrame(pd.get_dummies(Income['relationship']))\n",
    "Name_Dummy.columns\n",
    "Income[' Own-child']=Name_Dummy[' Own-child']\n",
    "Income[' Unmarried']=Name_Dummy[' Unmarried']\n",
    "Income[' Wife']=Name_Dummy[' Wife']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Name_Dummy=pd.DataFrame(pd.get_dummies(Income['race']))\n",
    "Name_Dummy.columns\n",
    "Income[' Other']=Name_Dummy[' Other']\n",
    "Income[' White']=Name_Dummy[' White']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Name_Dummy=pd.DataFrame(pd.get_dummies(Income['sex']))\n",
    "Name_Dummy.columns\n",
    "Income[' Female']=Name_Dummy[' Female']\n",
    "Income[' Male']=Name_Dummy[' Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Name_Dummy=pd.DataFrame(pd.get_dummies(Income['nativeCountry']))\n",
    "Name_Dummy.columns\n",
    "Income[' Cambodia']=Name_Dummy[' Cambodia']\n",
    "Income[' Canada']=Name_Dummy[' Canada']\n",
    "Income[' China']=Name_Dummy[' China']\n",
    "Income[' Columbia']=Name_Dummy[' Columbia']\n",
    "Income[' Cuba']=Name_Dummy[' Cuba']\n",
    "Income[' Dominican-Republic']=Name_Dummy[' Dominican-Republic']\n",
    "Income[' Ecuador']=Name_Dummy[' Ecuador']\n",
    "Income[' El-Salvador']=Name_Dummy[' El-Salvador']\n",
    "Income[' England']=Name_Dummy[' England']\n",
    "Income[' France']=Name_Dummy[' France']\n",
    "Income[' Germany']=Name_Dummy[' Germany']\n",
    "Income[' Greece']=Name_Dummy[' Greece']\n",
    "Income[' Guatemala']=Name_Dummy[' Guatemala']\n",
    "Income[' Haiti']=Name_Dummy[' Haiti']\n",
    "Income[' Holand-Netherlands']=Name_Dummy[' Holand-Netherlands']\n",
    "Income[' Honduras']=Name_Dummy[' Honduras']\n",
    "Income[' Hong']=Name_Dummy[' Hong']\n",
    "Income[' Hungary']=Name_Dummy[' Hungary']\n",
    "Income[' India']=Name_Dummy[' India']\n",
    "Income[' Iran']=Name_Dummy[' Iran']\n",
    "Income[' Ireland']=Name_Dummy[' Ireland']\n",
    "Income[' Italy']=Name_Dummy[' Italy']\n",
    "Income[' Jamaica']=Name_Dummy[' Jamaica']\n",
    "Income[' Japan']=Name_Dummy[' Japan']\n",
    "Income[' Laos']=Name_Dummy[' Laos']\n",
    "Income[' Mexico']=Name_Dummy[' Mexico']\n",
    "Income[' Nicaragua']=Name_Dummy[' Nicaragua']\n",
    "Income[' Outlying-US(Guam-USVI-etc)']=Name_Dummy[' Outlying-US(Guam-USVI-etc)']\n",
    "Income[' Peru']=Name_Dummy[' Peru']\n",
    "Income[' Philippines']=Name_Dummy[' Philippines']\n",
    "Income[' Poland']=Name_Dummy[' Poland']\n",
    "Income[' Portugal']=Name_Dummy[' Portugal']\n",
    "Income[' Puerto-Rico']=Name_Dummy[' Puerto-Rico']\n",
    "Income[' Scotland']=Name_Dummy[' Scotland']\n",
    "Income[' South']=Name_Dummy[' South']\n",
    "Income[' Taiwan']=Name_Dummy[' Taiwan']\n",
    "Income[' Thailand']=Name_Dummy[' Thailand']\n",
    "Income[' Trinadad&Tobago']=Name_Dummy[' Trinadad&Tobago']\n",
    "Income[' United-States']=Name_Dummy[' United-States']\n",
    "Income[' Vietnam']=Name_Dummy[' Vietnam']\n",
    "Income[' Yugoslavia']=Name_Dummy[' Yugoslavia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Income['workClass']\n",
    "del Income['maritalStatus']\n",
    "del Income['occupation']\n",
    "del Income['relationship']\n",
    "del Income['race']\n",
    "del Income['sex']\n",
    "del Income['nativeCountry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['income', 'age', 'educationNum', 'capitalGain', 'capitalLoss',\n",
       "       'hoursPerWeek', ' Federal-gov', ' Local-gov', ' Never-worked',\n",
       "       ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov',\n",
       "       ' Without-pay', ' Divorced', ' Married-AF-spouse',\n",
       "       ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married',\n",
       "       ' Separated', ' Widowed', ' Exec-managerial', ' Farming-fishing',\n",
       "       ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service',\n",
       "       ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support',\n",
       "       ' Transport-moving', ' Own-child', ' Unmarried', ' Wife', ' Other',\n",
       "       ' White', ' Female', ' Male', ' Cambodia', ' Canada', ' China',\n",
       "       ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador',\n",
       "       ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti',\n",
       "       ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India',\n",
       "       ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico',\n",
       "       ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines',\n",
       "       ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South',\n",
       "       ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States',\n",
       "       ' Vietnam', ' Yugoslavia'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Income.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Income[\"age_z\"]=pd.DataFrame((Income[\"age\"]-Income[\"age\"].mean())/Income[\"age\"].std())\n",
    "Income[\"educationNum_z\"]=pd.DataFrame((Income[\"educationNum\"]-Income[\"educationNum\"].mean())/Income[\"educationNum\"].std())\n",
    "Income[\"capitalGain_z\"]=pd.DataFrame((Income[\"capitalGain\"]-Income[\"capitalGain\"].mean())/Income[\"capitalGain\"].std())\n",
    "Income[\"capitalLoss_z\"]=pd.DataFrame((Income[\"capitalLoss\"]-Income[\"capitalLoss\"].mean())/Income[\"capitalLoss\"].std())\n",
    "Income[\"hoursPerWeek_z\"]=pd.DataFrame((Income[\"hoursPerWeek\"]-Income[\"hoursPerWeek\"].mean())/Income[\"hoursPerWeek\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Income[\"age\"]\n",
    "del Income[\"educationNum\"]\n",
    "del Income[\"capitalGain\"]\n",
    "del Income[\"capitalLoss\"]\n",
    "del Income[\"hoursPerWeek\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will prevent large outliers from having too much influence on the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Turn Prediction Variable Into Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "Income['income'] = le_dep.fit_transform(Income['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>Federal-gov</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Never-worked</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-emp-inc</th>\n",
       "      <th>Self-emp-not-inc</th>\n",
       "      <th>State-gov</th>\n",
       "      <th>Without-pay</th>\n",
       "      <th>Divorced</th>\n",
       "      <th>...</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Trinadad&amp;Tobago</th>\n",
       "      <th>United-States</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yugoslavia</th>\n",
       "      <th>age_z</th>\n",
       "      <th>educationNum_z</th>\n",
       "      <th>capitalGain_z</th>\n",
       "      <th>capitalLoss_z</th>\n",
       "      <th>hoursPerWeek_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030670</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837096</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-2.222119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.042641</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.057031</td>\n",
       "      <td>-1.197440</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.775756</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.115953</td>\n",
       "      <td>1.523415</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.763785</td>\n",
       "      <td>-1.974828</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-1.979153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983719</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.369514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.555822</td>\n",
       "      <td>1.523415</td>\n",
       "      <td>1.761115</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.774456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   income   Federal-gov   Local-gov   Never-worked   Private   Self-emp-inc  \\\n",
       "0       0             0           0              0         0              0   \n",
       "1       0             0           0              0         0              0   \n",
       "2       0             0           0              0         1              0   \n",
       "3       0             0           0              0         1              0   \n",
       "4       0             0           0              0         1              0   \n",
       "5       0             0           0              0         1              0   \n",
       "6       0             0           0              0         1              0   \n",
       "7       1             0           0              0         0              0   \n",
       "8       1             0           0              0         1              0   \n",
       "9       1             0           0              0         1              0   \n",
       "\n",
       "    Self-emp-not-inc   State-gov   Without-pay   Divorced       ...        \\\n",
       "0                  0           1             0          0       ...         \n",
       "1                  1           0             0          0       ...         \n",
       "2                  0           0             0          1       ...         \n",
       "3                  0           0             0          0       ...         \n",
       "4                  0           0             0          0       ...         \n",
       "5                  0           0             0          0       ...         \n",
       "6                  0           0             0          0       ...         \n",
       "7                  1           0             0          0       ...         \n",
       "8                  0           0             0          0       ...         \n",
       "9                  0           0             0          0       ...         \n",
       "\n",
       "    Thailand   Trinadad&Tobago   United-States   Vietnam   Yugoslavia  \\\n",
       "0          0                 0               1         0            0   \n",
       "1          0                 0               1         0            0   \n",
       "2          0                 0               1         0            0   \n",
       "3          0                 0               1         0            0   \n",
       "4          0                 0               0         0            0   \n",
       "5          0                 0               1         0            0   \n",
       "6          0                 0               0         0            0   \n",
       "7          0                 0               1         0            0   \n",
       "8          0                 0               1         0            0   \n",
       "9          0                 0               1         0            0   \n",
       "\n",
       "      age_z  educationNum_z  capitalGain_z  capitalLoss_z  hoursPerWeek_z  \n",
       "0  0.030670        1.134721       0.148451      -0.216656       -0.035429  \n",
       "1  0.837096        1.134721      -0.145918      -0.216656       -2.222119  \n",
       "2 -0.042641       -0.420053      -0.145918      -0.216656       -0.035429  \n",
       "3  1.057031       -1.197440      -0.145918      -0.216656       -0.035429  \n",
       "4 -0.775756        1.134721      -0.145918      -0.216656       -0.035429  \n",
       "5 -0.115953        1.523415      -0.145918      -0.216656       -0.035429  \n",
       "6  0.763785       -1.974828      -0.145918      -0.216656       -1.979153  \n",
       "7  0.983719       -0.420053      -0.145918      -0.216656        0.369514  \n",
       "8 -0.555822        1.523415       1.761115      -0.216656        0.774456  \n",
       "9  0.250604        1.134721       0.555205      -0.216656       -0.035429  \n",
       "\n",
       "[10 rows x 79 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Income.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9769, 78)\n",
      "(22792, 78)\n",
      "(9769,)\n",
      "(22792,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    Income.iloc[:,1:].values, Income.iloc[:,0].values, test_size=0.30, random_state=0)\n",
    "\n",
    "print(features_test.shape)\n",
    "print(features_train.shape)\n",
    "print(target_test.shape)\n",
    "print(target_train.shape)\n",
    "\n",
    "##The training and test sets are created. Now it's time to run the algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Entries\n",
    "#### True positives - Accuratly predicting income > 50K.\n",
    "#### True negatives - Accuratly predicting income <= 50K.\n",
    "#### False positives - Incorrectly predicting income > 50K, when it is <= 50K.\n",
    "#### False negatives - Incorrectly predicting income <= 50K, when it is > 50K.\n",
    "\n",
    "## Residual Measures\n",
    "#### Accuracy - Overall how good the model is at predicting both income > 50K and income <= 50K.\n",
    "#### Precision - When predicting income > 50K, how often this true.\n",
    "#### Recall - Of all the observations where income > 50K, how often income > 50K is predicted.\n",
    "#### Specificity - When predicting income <= 50K, how often this true.\n",
    "\n",
    "#### Hint: In the writeup, \"precision\" = \"Targetting Rate\" and \"recall\" = \"Prospect Identification Rate,\" as these terms are easier to understand in a marketing context.\n",
    "\n",
    "## Presumptions: \n",
    "#### 1) Predicting whether an individual's income > 50K is used for marketing purposes. Individuals with income > 50K have a high propensity to become customers and individuals with income <= 50K can't afford the products/services.\n",
    "#### 2) Acquiring customers' information has a cost (i.e. it costs money to purchase mailing lists, etc.)\n",
    "#### 3) Targeting customers whose income <= 50K will result in a negative Return On Investment (ROI.)\n",
    "\n",
    "#### These presumptions would be verified in a real-world example.\n",
    "\n",
    "## Based on the presumptions above: \n",
    "#### 1) Models will be selected based on precision and sensitivity.\n",
    "#### 2) Precision is the most important measure. When spending money on an advertising campaign, it's important that it's reaching the target market (i.e. income > 50K)\n",
    "#### 3) Recall is the second most important measure. Throwing away good prospect is wasting money. However, it's better to have a slightly higher precision and slightly lower sensitivity. This is a balancing act.\n",
    "\n",
    "## Precision measured against 24.081%\n",
    "#### 24.081% of the population have income > 50K. Therefore, this precision can be achieved without an algorithm. A significant increase over 24.081% represents the lift, and the value that this analysis brings to a marketing organization. The value can be further quantified by factoring in how much revenue each percent increase of precision brings.\n",
    "\n",
    "#### Source: http://scaryscientist.blogspot.com/2016/03/confusion-matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree \n",
    "clf_dt = tree.DecisionTreeClassifier()\n",
    "#Call up the model to see the parameters you can tune (and their default setting)\n",
    "print(clf_dt)\n",
    "#Fit clf to the training data\n",
    "clf_dt = clf_dt.fit(features_train, target_train)\n",
    "#Predict clf DT model again test data\n",
    "target_predicted_dt = clf_dt.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.816153137476\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88      7407\n",
      "          1       0.62      0.61      0.61      2362\n",
      "\n",
      "avg / total       0.81      0.82      0.82      9769\n",
      "\n",
      "[[6539  868]\n",
      " [ 928 1434]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "print(classification_report(target_test, target_predicted_dt))\n",
    "print(confusion_matrix(target_test, target_predicted_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.80921053  0.83508772  0.82850877  0.82580079  0.81000439  0.81219833\n",
      "  0.82272927  0.82053532  0.81395349  0.82265145]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82006800545989889"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_dt, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low precision (63%) and low recall (61%)\n",
    "#### This model is stable, but it isn't a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree \n",
    "clf_dt = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "print(clf_dt)\n",
    "#Fit clf to the training data\n",
    "clf_dt = clf_dt.fit(features_train, target_train)\n",
    "#Predict clf DT model again test data\n",
    "target_predicted_dt = clf_dt.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.821578462483\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.89      0.88      7407\n",
      "          1       0.64      0.61      0.62      2362\n",
      "\n",
      "avg / total       0.82      0.82      0.82      9769\n",
      "\n",
      "[[6584  823]\n",
      " [ 920 1442]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "print(classification_report(target_test, target_predicted_dt))\n",
    "print(confusion_matrix(target_test, target_predicted_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.82236842  0.83289474  0.82368421  0.81965774  0.81834138  0.80430013\n",
      "  0.82316806  0.81219833  0.81307591  0.81738367]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8187072591619774"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_dt, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar results as default decision tree model. Conclusion the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='random')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree \n",
    "clf_dt = tree.DecisionTreeClassifier(splitter=\"random\")\n",
    "print(clf_dt)\n",
    "#Fit clf to the training data\n",
    "clf_dt = clf_dt.fit(features_train, target_train)\n",
    "#Predict clf DT model again test data\n",
    "target_predicted_dt = clf_dt.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.815743678985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.88      7407\n",
      "          1       0.62      0.60      0.61      2362\n",
      "\n",
      "avg / total       0.81      0.82      0.81      9769\n",
      "\n",
      "[[6552  855]\n",
      " [ 945 1417]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "print(classification_report(target_test, target_predicted_dt))\n",
    "print(confusion_matrix(target_test, target_predicted_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.81184211  0.81710526  0.825       0.80342255  0.81000439  0.80912681\n",
      "  0.80737165  0.82053532  0.80605529  0.81123793]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81217013122244786"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_dt, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar results as default decision tree model. Conclusion the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree \n",
    "clf_dt = tree.DecisionTreeClassifier(min_samples_split=5)\n",
    "print(clf_dt)\n",
    "#Fit clf to the training data\n",
    "clf_dt = clf_dt.fit(features_train, target_train)\n",
    "#Predict clf DT model again test data\n",
    "target_predicted_dt = clf_dt.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.832224383253\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.89      7407\n",
      "          1       0.67      0.60      0.63      2362\n",
      "\n",
      "avg / total       0.83      0.83      0.83      9769\n",
      "\n",
      "[[6712  695]\n",
      " [ 944 1418]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "print(classification_report(target_test, target_predicted_dt))\n",
    "print(confusion_matrix(target_test, target_predicted_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.82412281  0.84254386  0.8372807   0.83545415  0.8214129   0.82755595\n",
      "  0.83150505  0.82272927  0.81570864  0.83274802]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82910613429820812"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_dt, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision Increased. Moderate evidence that the model may be unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh_kn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh_kn3 = neigh_kn3.fit(features_train, target_train)\n",
    "target_predicted_neigh_kn3 = neigh_kn3.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.830381820043\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.90      0.89      7407\n",
      "          1       0.66      0.61      0.63      2362\n",
      "\n",
      "avg / total       0.83      0.83      0.83      9769\n",
      "\n",
      "[[6671  736]\n",
      " [ 921 1441]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_neigh_kn3))\n",
    "print(classification_report(target_test, target_predicted_neigh_kn3))\n",
    "print(confusion_matrix(target_test, target_predicted_neigh_kn3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.83464912  0.83289474  0.83289474  0.8372093   0.83106626  0.82580079\n",
      "  0.82492321  0.82492321  0.82887231  0.84021071]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83134443932052038"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(neigh_kn3, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN results similar as default decision tree model. Conclusion the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh_kn = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_kn = neigh_kn.fit(features_train, target_train)\n",
    "target_predicted_neigh_kn = neigh_kn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.847374347426\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90      7407\n",
      "          1       0.72      0.60      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6856  551]\n",
      " [ 940 1422]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_neigh_kn))\n",
    "print(classification_report(target_test, target_predicted_neigh_kn))\n",
    "print(confusion_matrix(target_test, target_predicted_neigh_kn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83947368  0.84868421  0.84605263  0.84642387  0.83238262  0.83413778\n",
      "  0.82755595  0.83589294  0.82053532  0.85118525]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83823242539376497"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(neigh_kn, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model has a good boost in precision (72% total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh_kn = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh_kn = neigh_kn.fit(features_train, target_train)\n",
    "target_predicted_neigh_kn = neigh_kn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.847374347426\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90      7407\n",
      "          1       0.72      0.60      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6856  551]\n",
      " [ 940 1422]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_neigh_kn))\n",
    "print(classification_report(target_test, target_predicted_neigh_kn))\n",
    "print(confusion_matrix(target_test, target_predicted_neigh_kn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.84868421  0.85350877  0.84649123  0.85563844  0.83589294  0.83501536\n",
      "  0.84028082  0.84993418  0.83282141  0.85074627]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84490136296876384"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(neigh_kn, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model has a good boost in precision (72%). Also, more K's is better (10 vs. 5) and having more K's means each prediction has more observations (i.e. a simplier model that is less likely to overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh_kn = KNeighborsClassifier(n_neighbors=20)\n",
    "neigh_kn = neigh_kn.fit(features_train, target_train)\n",
    "target_predicted_neigh_kn = neigh_kn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.847374347426\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90      7407\n",
      "          1       0.72      0.60      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6856  551]\n",
      " [ 940 1422]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_neigh_kn))\n",
    "print(classification_report(target_test, target_predicted_neigh_kn))\n",
    "print(confusion_matrix(target_test, target_predicted_neigh_kn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.85263158  0.85789474  0.85087719  0.86265906  0.84028082  0.83633172\n",
      "  0.84379114  0.85081176  0.83457657  0.84899034]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84788449262104582"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(neigh_kn, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model appears to preforming well. However, these cross validated scores suggests the model may be overfitting. KNN has a tendency to overfit. Therefore, another model with similar/better precision/recall would be preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
      "            oob_score=True, random_state=None, verbose=0, warm_start=False)\n",
      "Random Forfest Accuracy 0.84716961818\n"
     ]
    }
   ],
   "source": [
    "#Train Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True, class_weight=\"balanced\")\n",
    "print(rf)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"Random Forest Accuracy\", accuracy_score(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score 0.84716961818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      7407\n",
      "          1       0.70      0.64      0.67      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6756  651]\n",
      " [ 842 1520]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "print(classification_report(target_test, target_predicted_rf))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each Random Forest [ 0.85131579  0.84649123  0.85263158  0.85519965  0.83808688  0.84291356\n",
      "  0.83984204  0.84466871  0.83589294  0.8546971 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84617394727978179"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The random forest has great precision (70%) and the best recall thusfar. Moderate evidence from cross-validation that this model may be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Random Forest Accuracy 0.847271982803\n"
     ]
    }
   ],
   "source": [
    "#Train Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(criterion=\"entropy\")\n",
    "print(rf)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"Random Forest Accuracy\", accuracy_score(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score 0.847271982803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90      7407\n",
      "          1       0.72      0.60      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6854  553]\n",
      " [ 939 1423]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "print(classification_report(target_test, target_predicted_rf))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each Random Forest [ 0.84649123  0.84605263  0.85263158  0.85476086  0.84159719  0.8411584\n",
      "  0.84335235  0.84159719  0.84247477  0.8428446 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84529608026160274"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2% increase in precision and 4% drop in recall (precision is more important). Cross validation shows this model likely isn't overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Random Forest Accuracy 0.841232470058\n"
     ]
    }
   ],
   "source": [
    "#Train Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_features=1)\n",
    "print(rf)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"Random Forest Accuracy\", accuracy_score(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score 0.841232470058\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.90      7407\n",
      "          1       0.71      0.58      0.64      2362\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "[[6841  566]\n",
      " [ 985 1377]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "print(classification_report(target_test, target_predicted_rf))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each Random Forest [ 0.83991228  0.83157895  0.84780702  0.84335235  0.82580079  0.83194384\n",
      "  0.82799473  0.83677051  0.82667837  0.84021071]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83520495447413501"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop in precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=20, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Random Forest Accuracy 0.847579076671\n"
     ]
    }
   ],
   "source": [
    "#Train Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_features=20)\n",
    "print(rf)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"Random Forest Accuracy\", accuracy_score(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score 0.847579076671\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7407\n",
      "          1       0.72      0.61      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6841  566]\n",
      " [ 923 1439]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "print(classification_report(target_test, target_predicted_rf))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each Random Forest [ 0.84517544  0.84605263  0.8495614   0.84817903  0.84203598  0.84028082\n",
      "  0.84159719  0.84949539  0.84159719  0.84416155]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8448136626621997"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High precision, recall and it appears to not be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, class_weight='balanced')\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "target_predicted_SVC=clf_linSVC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score 0.805916675197\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.79      0.86      7407\n",
      "          1       0.57      0.86      0.68      2362\n",
      "\n",
      "avg / total       0.85      0.81      0.82      9769\n",
      "\n",
      "[[5851 1556]\n",
      " [ 340 2022]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Score\", accuracy_score(target_test, target_predicted_SVC))\n",
    "print(classification_report(target_test, target_predicted_SVC))\n",
    "print(confusion_matrix(target_test, target_predicted_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.85701754  0.85964912  0.84517544  0.86046512  0.84598508  0.84203598\n",
      "  0.84554629  0.8530057   0.83369899  0.85689201]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84994712812221462"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_linSVC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poor precision (57%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC()\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "target_predicted_SVC=clf_linSVC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score 0.851059473846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90      7407\n",
      "          1       0.73      0.60      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.85      9769\n",
      "\n",
      "[[6894  513]\n",
      " [ 942 1420]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Score\", accuracy_score(target_test, target_predicted_SVC))\n",
    "print(classification_report(target_test, target_predicted_SVC))\n",
    "print(confusion_matrix(target_test, target_predicted_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.85657895  0.85964912  0.84517544  0.86046512  0.84598508  0.84203598\n",
      "  0.84554629  0.8530057   0.83369899  0.85689201]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84990326847309183"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_linSVC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Best precision thusfar. Moderate evidence there is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=10.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "target_predicted_SVM=clf_lin.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score 0.793940014331\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.77      0.85      7407\n",
      "          1       0.55      0.86      0.67      2362\n",
      "\n",
      "avg / total       0.85      0.79      0.81      9769\n",
      "\n",
      "[[5715 1692]\n",
      " [ 321 2041]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Score\", accuracy_score(target_test, target_predicted_SVM))\n",
    "print(classification_report(target_test, target_predicted_SVM))\n",
    "print(confusion_matrix(target_test, target_predicted_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poor precision. This model wasn't cross validated, as this model takes a lot time to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVMs) - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_rbf = SVC(kernel='rbf')\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "target_predicted_rbf=clf_rbf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score 0.805507216706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.78      0.86      7407\n",
      "          1       0.56      0.87      0.68      2362\n",
      "\n",
      "avg / total       0.86      0.81      0.82      9769\n",
      "\n",
      "[[5804 1603]\n",
      " [ 297 2065]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Score\", accuracy_score(target_test, target_predicted_rbf))\n",
    "print(classification_report(target_test, target_predicted_rbf))\n",
    "print(confusion_matrix(target_test, target_predicted_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poor precision and great recall. However, precision is more important than recall.\n",
    "#### This model wasn't cross validated, as this model takes a lot time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_rbf = SVC(kernel='rbf', C=1.0, degree=3, class_weight='balanced',gamma=0.1)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "target_predicted_rbf=clf_rbf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score 0.805507216706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.78      0.86      7407\n",
      "          1       0.56      0.87      0.68      2362\n",
      "\n",
      "avg / total       0.86      0.81      0.82      9769\n",
      "\n",
      "[[5804 1603]\n",
      " [ 297 2065]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Score\", accuracy_score(target_test, target_predicted_rbf))\n",
    "print(classification_report(target_test, target_predicted_rbf))\n",
    "print(confusion_matrix(target_test, target_predicted_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poor precision and great recall. However, precision is more important than recall.\n",
    "#### This model wasn't cross-validated, as this model takes a lot time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_rbf = SVC(kernel='rbf', C=.25, degree=3, class_weight='balanced',gamma=0.1)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "target_predicted_rbf=clf_rbf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score 0.805200122838\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.78      0.86      7407\n",
      "          1       0.56      0.87      0.68      2362\n",
      "\n",
      "avg / total       0.86      0.81      0.82      9769\n",
      "\n",
      "[[5803 1604]\n",
      " [ 299 2063]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Score\", accuracy_score(target_test, target_predicted_rbf))\n",
    "print(classification_report(target_test, target_predicted_rbf))\n",
    "print(confusion_matrix(target_test, target_predicted_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poor precision and great recall. However, precision is more important than recall.\n",
    "#### This model wasn't cross-validated, as this model takes a lot time to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifical Neuralogical Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "       epsilon=1e-08, hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "       warm_start=False)\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.852083120074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.92      0.90      7407\n",
      "          1       0.72      0.63      0.67      2362\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "[[6835  572]\n",
      " [ 873 1489]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.8627193   0.86491228  0.8504386   0.86616937  0.84686266  0.8530057\n",
      "  0.85827117  0.85388328  0.84730145  0.86172081]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85652846207250055"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model has both good percision and recall. ANN models are also very complex to explain. Therefore, a model (precision and recall combination) needs to be produced, before justifying this model over a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier()\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.856996621967\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.93      0.91      7407\n",
      "          1       0.74      0.63      0.68      2362\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "[[6878  529]\n",
      " [ 868 1494]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.85964912  0.8622807   0.85570175  0.86002633  0.85651602  0.84642387\n",
      "  0.8490566   0.85563844  0.83940325  0.8595259 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85442219808341213"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increased precions and decreased recall from last model (good trade off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(5,5))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.853209130924\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.92      0.90      7407\n",
      "          1       0.72      0.65      0.68      2362\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "[[6810  597]\n",
      " [ 837 1525]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.86842105  0.86184211  0.84824561  0.86222027  0.85212813  0.85037297\n",
      "  0.85212813  0.85783238  0.84554629  0.85645303]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85551899711527157"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(10,10))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.852287849319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.92      0.90      7407\n",
      "          1       0.72      0.63      0.67      2362\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "[[6833  574]\n",
      " [ 869 1493]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.86666667  0.86973684  0.85701754  0.86792453  0.85783238  0.8490566\n",
      "  0.85476086  0.85958754  0.84642387  0.85864794]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85876547726564956"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(5,5,5))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.850650015355\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7407\n",
      "          1       0.72      0.62      0.67      2362\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "[[6842  565]\n",
      " [ 894 1468]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.86359649  0.86403509  0.84078947  0.86485301  0.85344449  0.8530057\n",
      "  0.85168934  0.85651602  0.84379114  0.85513608]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85468568297637793"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(20,20,20))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.853311495547\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.92      0.91      7407\n",
      "          1       0.73      0.63      0.68      2362\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "[[6845  562]\n",
      " [ 871 1491]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.85921053  0.86491228  0.84912281  0.86222027  0.84028082  0.85081176\n",
      "  0.85651602  0.85783238  0.84730145  0.85513608]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8543344401259434"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(40,40,40))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.838673354489\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.89      0.89      7407\n",
      "          1       0.66      0.69      0.67      2362\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "[[6560  847]\n",
      " [ 729 1633]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.84780702  0.85307018  0.84517544  0.85212813  0.83808688  0.83896446\n",
      "  0.84949539  0.84642387  0.83194384  0.84811238]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84512075733864422"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(40,40,40,40))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.846145971952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7407\n",
      "          1       0.71      0.62      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6799  608]\n",
      " [ 895 1467]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.8495614   0.84736842  0.84517544  0.84861781  0.84028082  0.83896446\n",
      "  0.84203598  0.84949539  0.83018868  0.8476734 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84393618113797975"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(40,40,40,40,40,40,40))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.845531784215\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      7407\n",
      "          1       0.69      0.65      0.67      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6731  676]\n",
      " [ 833 1529]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.85482456  0.85482456  0.85131579  0.84379114  0.83282141  0.84291356\n",
      "  0.84774024  0.84071961  0.83062747  0.84635645]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8445934792251315"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(50,50,50,50))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.8427679394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      7407\n",
      "          1       0.69      0.63      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "[[6747  660]\n",
      " [ 876 1486]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.84912281  0.83947368  0.84210526  0.85256692  0.83413778  0.81044318\n",
      "  0.84642387  0.84291356  0.83194384  0.8546971 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84038279926934334"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "clf_NN.fit(features_train, target_train)\n",
    "target_predicted_NN = clf_NN.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Score 0.84972873375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      7407\n",
      "          1       0.70      0.65      0.68      2362\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "[[6759  648]\n",
      " [ 820 1542]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN Score\", accuracy_score(target_test, target_predicted_NN))\n",
    "print(classification_report(target_test, target_predicted_NN))\n",
    "print(confusion_matrix(target_test, target_predicted_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.86008772  0.86798246  0.85219298  0.84817903  0.84422993  0.84993418\n",
      "  0.84379114  0.85651602  0.84071961  0.84942932]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85130623809416728"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD = SGDClassifier()\n",
    "SGD.fit(features_train, target_train)\n",
    "target_predicted_SGD = SGD.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.834783498823\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.87      0.89      7407\n",
      "          1       0.64      0.73      0.68      2362\n",
      "\n",
      "avg / total       0.84      0.83      0.84      9769\n",
      "\n",
      "[[6442  965]\n",
      " [ 649 1713]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_SGD))\n",
    "print(classification_report(target_test, target_predicted_SGD))\n",
    "print(confusion_matrix(target_test, target_predicted_SGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.84254386  0.84517544  0.78070175  0.84949539  0.8411584   0.8293111\n",
      "  0.84335235  0.85168934  0.72926722  0.80597015]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82186650061854427"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(SGD, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model is unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD = SGDClassifier(loss='log')\n",
    "SGD.fit(features_train, target_train)\n",
    "target_predicted_SGD = SGD.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.846760159689\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.93      0.90      7407\n",
      "          1       0.73      0.59      0.65      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6885  522]\n",
      " [ 975 1387]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_SGD))\n",
    "print(classification_report(target_test, target_predicted_SGD))\n",
    "print(confusion_matrix(target_test, target_predicted_SGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.84166667  0.81096491  0.8377193   0.84335235  0.84159719  0.82623958\n",
      "  0.82448442  0.84774024  0.8332602   0.84855136]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83555762178515347"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(SGD, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model is unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD = SGDClassifier(penalty='elasticnet')\n",
    "SGD.fit(features_train, target_train)\n",
    "target_predicted_SGD = SGD.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.843279762514\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90      7407\n",
      "          1       0.75      0.52      0.62      2362\n",
      "\n",
      "avg / total       0.84      0.84      0.83      9769\n",
      "\n",
      "[[7003  404]\n",
      " [1127 1235]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_SGD))\n",
    "print(classification_report(target_test, target_predicted_SGD))\n",
    "print(confusion_matrix(target_test, target_predicted_SGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.81315789  0.8495614   0.82280702  0.84466871  0.83062747  0.82887231\n",
      "  0.84071961  0.85037297  0.83413778  0.82572432]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83406494945167997"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(SGD, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model is unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ABC = AdaBoostClassifier()\n",
    "ABC.fit(features_train, target_train)\n",
    "target_predicted_ABC = ABC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.859248643669\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.93      0.91      7407\n",
      "          1       0.75      0.63      0.68      2362\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "[[6917  490]\n",
      " [ 885 1477]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_ABC))\n",
    "print(classification_report(target_test, target_predicted_ABC))\n",
    "print(confusion_matrix(target_test, target_predicted_ABC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.85745614  0.86666667  0.85657895  0.86660816  0.85432207  0.85870996\n",
      "  0.85870996  0.86529179  0.8490566   0.86567164]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8599071948173499"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(ABC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This appears to be the best model thusfar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ABC = AdaBoostClassifier(n_estimators=100)\n",
    "ABC.fit(features_train, target_train)\n",
    "target_predicted_ABC = ABC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.861603029993\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.91      7407\n",
      "          1       0.76      0.62      0.69      2362\n",
      "\n",
      "avg / total       0.86      0.86      0.86      9769\n",
      "\n",
      "[[6941  466]\n",
      " [ 886 1476]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_ABC))\n",
    "print(classification_report(target_test, target_predicted_ABC))\n",
    "print(confusion_matrix(target_test, target_predicted_ABC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.86315789  0.87763158  0.86315789  0.87143484  0.85914875  0.86441422\n",
      "  0.86441422  0.86748574  0.85519965  0.86611062]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86521554029201098"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(ABC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ABC = AdaBoostClassifier(n_estimators=400)\n",
    "ABC.fit(features_train, target_train)\n",
    "target_predicted_ABC = ABC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.867540178114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.91      7407\n",
      "          1       0.77      0.65      0.70      2362\n",
      "\n",
      "avg / total       0.86      0.87      0.86      9769\n",
      "\n",
      "[[6947  460]\n",
      " [ 834 1528]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_ABC))\n",
    "print(classification_report(target_test, target_predicted_ABC))\n",
    "print(confusion_matrix(target_test, target_predicted_ABC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.87324561  0.88157895  0.86710526  0.87319     0.86353664  0.86485301\n",
      "  0.86704695  0.87099605  0.86002633  0.87006146]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8691640250826177"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(ABC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "BC = BaggingClassifier()\n",
    "BC.fit(features_train, target_train)\n",
    "target_predicted_BC = BC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.842665574777\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7407\n",
      "          1       0.70      0.61      0.65      2362\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "[[6802  605]\n",
      " [ 932 1430]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_BC))\n",
    "print(classification_report(target_test, target_predicted_BC))\n",
    "print(confusion_matrix(target_test, target_predicted_BC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.84649123  0.84385965  0.85394737  0.84642387  0.84028082  0.83545415\n",
      "  0.83589294  0.84422993  0.83501536  0.84064969]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84222449984410264"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(BC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stable. Good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "BC = BaggingClassifier(n_estimators=20)\n",
    "BC.fit(features_train, target_train)\n",
    "target_predicted_BC = BC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.846043607329\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7407\n",
      "          1       0.71      0.62      0.66      2362\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "[[6790  617]\n",
      " [ 887 1475]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_BC))\n",
    "print(classification_report(target_test, target_predicted_BC))\n",
    "print(confusion_matrix(target_test, target_predicted_BC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.84122807  0.84868421  0.84912281  0.84993418  0.84203598  0.83457657\n",
      "  0.83764809  0.84686266  0.83984204  0.84152766]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84314622608899159"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(BC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slight improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "BC = BaggingClassifier(max_samples=5)\n",
    "BC.fit(features_train, target_train)\n",
    "target_predicted_BC = BC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.760773876548\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86      7407\n",
      "          1       0.69      0.02      0.04      2362\n",
      "\n",
      "avg / total       0.74      0.76      0.66      9769\n",
      "\n",
      "[[7386   21]\n",
      " [2316   46]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_BC))\n",
    "print(classification_report(target_test, target_predicted_BC))\n",
    "print(confusion_matrix(target_test, target_predicted_BC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.77236842  0.75964912  0.79736842  0.75954366  0.77841158  0.75866608\n",
      "  0.76261518  0.79464677  0.76963581  0.75987709]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77127821373937044"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(BC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unstable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "BC = BaggingClassifier(max_samples=50)\n",
    "BC.fit(features_train, target_train)\n",
    "target_predicted_BC = BC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.824547036544\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.89      7407\n",
      "          1       0.75      0.41      0.53      2362\n",
      "\n",
      "avg / total       0.82      0.82      0.80      9769\n",
      "\n",
      "[[7087  320]\n",
      " [1394  968]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_BC))\n",
    "print(classification_report(target_test, target_predicted_BC))\n",
    "print(confusion_matrix(target_test, target_predicted_BC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.81403509  0.80745614  0.81885965  0.83677051  0.81570864  0.81834138\n",
      "  0.83194384  0.83852567  0.81965774  0.81387182]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82151704786924928"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(BC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unstable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(features_train, target_train)\n",
    "target_predicted_GBC = GBC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.864469239431\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.91      7407\n",
      "          1       0.77      0.62      0.69      2362\n",
      "\n",
      "avg / total       0.86      0.86      0.86      9769\n",
      "\n",
      "[[6977  430]\n",
      " [ 894 1468]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_GBC))\n",
    "print(classification_report(target_test, target_predicted_GBC))\n",
    "print(confusion_matrix(target_test, target_predicted_GBC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.87105263  0.87105263  0.86184211  0.87626152  0.86134269  0.86134269\n",
      "  0.86880211  0.87538394  0.85125055  0.8665496 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86648804748734087"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(GBC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unstable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier(loss='exponential')\n",
    "GBC.fit(features_train, target_train)\n",
    "target_predicted_GBC = GBC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.863855051694\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.91      7407\n",
      "          1       0.77      0.62      0.69      2362\n",
      "\n",
      "avg / total       0.86      0.86      0.86      9769\n",
      "\n",
      "[[6963  444]\n",
      " [ 886 1476]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_GBC))\n",
    "print(classification_report(target_test, target_predicted_GBC))\n",
    "print(confusion_matrix(target_test, target_predicted_GBC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.86973684  0.87280702  0.86315789  0.87055726  0.85870996  0.86353664\n",
      "  0.86529179  0.87670031  0.85212813  0.86567164]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86582974856899531"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(GBC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unstable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier(n_estimators=200)\n",
    "GBC.fit(features_train, target_train)\n",
    "target_predicted_GBC = GBC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.867949636606\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.92      7407\n",
      "          1       0.77      0.64      0.70      2362\n",
      "\n",
      "avg / total       0.86      0.87      0.86      9769\n",
      "\n",
      "[[6963  444]\n",
      " [ 846 1516]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_GBC))\n",
    "print(classification_report(target_test, target_predicted_GBC))\n",
    "print(confusion_matrix(target_test, target_predicted_GBC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.87587719  0.87938596  0.86535088  0.87494515  0.86353664  0.86573058\n",
      "  0.87011847  0.87845546  0.86090391  0.87050044]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87048046890758646"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(GBC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model is moderatly-stable and performs well. The cross-validation shows it is stable; however, less complex models were unstable. Therefore, there isn't enough evidence to consider this model as stable. It may be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "ETC = ExtraTreeClassifier()\n",
    "ETC.fit(features_train, target_train)\n",
    "target_predicted_ETC = ETC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.804074111987\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.88      0.87      7407\n",
      "          1       0.60      0.56      0.58      2362\n",
      "\n",
      "avg / total       0.80      0.80      0.80      9769\n",
      "\n",
      "[[6540  867]\n",
      " [1047 1315]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_ETC))\n",
    "print(classification_report(target_test, target_predicted_ETC))\n",
    "print(confusion_matrix(target_test, target_predicted_ETC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.87587719  0.87938596  0.86535088  0.87494515  0.86353664  0.86573058\n",
      "  0.87011847  0.87845546  0.86090391  0.87050044]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87048046890758646"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(GBC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model is stable. Other models perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "ETC = ExtraTreeClassifier(criterion=\"entropy\")\n",
    "ETC.fit(features_train, target_train)\n",
    "target_predicted_ETC = ETC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.808987613881\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.89      0.88      7407\n",
      "          1       0.61      0.57      0.59      2362\n",
      "\n",
      "avg / total       0.80      0.81      0.81      9769\n",
      "\n",
      "[[6558  849]\n",
      " [1017 1345]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_ETC))\n",
    "print(classification_report(target_test, target_predicted_ETC))\n",
    "print(confusion_matrix(target_test, target_predicted_ETC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.87587719  0.87938596  0.86535088  0.87494515  0.86353664  0.86573058\n",
      "  0.87011847  0.87845546  0.86090391  0.87050044]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87048046890758646"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(GBC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model is stable. Other models perform better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "ETC = ExtraTreeClassifier(splitter='random')\n",
    "ETC.fit(features_train, target_train)\n",
    "target_predicted_ETC = ETC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.810625447845\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.88      7407\n",
      "          1       0.61      0.58      0.60      2362\n",
      "\n",
      "avg / total       0.81      0.81      0.81      9769\n",
      "\n",
      "[[6549  858]\n",
      " [ 992 1370]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_ETC))\n",
    "print(classification_report(target_test, target_predicted_ETC))\n",
    "print(confusion_matrix(target_test, target_predicted_ETC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.87587719  0.87938596  0.86535088  0.87494515  0.86353664  0.86573058\n",
      "  0.87011847  0.87845546  0.86090391  0.87050044]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87048046890758646"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(GBC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model is stable. Other models perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stacking (Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "VC = VotingClassifier(estimators=\n",
    "                     [('income', clf_dt),\n",
    "                      ('income', neigh_kn3)],\n",
    "                               voting='hard')\n",
    "VC.fit(features_train, target_train)\n",
    "target_predicted_VC = VC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.836933155901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90      7407\n",
      "          1       0.75      0.49      0.59      2362\n",
      "\n",
      "avg / total       0.83      0.84      0.82      9769\n",
      "\n",
      "[[7010  397]\n",
      " [1196 1166]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_VC))\n",
    "print(classification_report(target_test, target_predicted_VC))\n",
    "print(confusion_matrix(target_test, target_predicted_VC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.8377193   0.84517544  0.84210526  0.83984204  0.83940325  0.83633172\n",
      "  0.83194384  0.83369899  0.83238262  0.84460053]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83832029839959543"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(VC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model has high percision and low recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "VC = VotingClassifier(estimators=\n",
    "                     [('income', clf_dt),\n",
    "                      ('income', neigh_kn3)],\n",
    "                               voting='soft')\n",
    "VC.fit(features_train, target_train)\n",
    "target_predicted_VC = VC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.831712560139\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.89      7407\n",
      "          1       0.67      0.60      0.63      2362\n",
      "\n",
      "avg / total       0.83      0.83      0.83      9769\n",
      "\n",
      "[[6717  690]\n",
      " [ 954 1408]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_VC))\n",
    "print(classification_report(target_test, target_predicted_VC))\n",
    "print(confusion_matrix(target_test, target_predicted_VC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.82894737  0.84035088  0.83815789  0.83589294  0.82623958  0.82404563\n",
      "  0.83194384  0.83457657  0.82492321  0.83494293]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83200208366792661"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(VC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The precision is lowered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042884324432\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "VC = VotingClassifier(estimators=\n",
    "                     [('income', clf_dt),\n",
    "                      ('income', neigh_kn3)],\n",
    "                               voting='soft',\n",
    "                               n_jobs=3)\n",
    "VC.fit(features_train, target_train)\n",
    "target_predicted_VC = VC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score 0.83099600778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.89      7407\n",
      "          1       0.67      0.59      0.63      2362\n",
      "\n",
      "avg / total       0.83      0.83      0.83      9769\n",
      "\n",
      "[[6713  694]\n",
      " [ 957 1405]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Score\", accuracy_score(target_test, target_predicted_VC))\n",
    "print(classification_report(target_test, target_predicted_VC))\n",
    "print(confusion_matrix(target_test, target_predicted_VC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042781473480\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042884324320\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042839305856\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042744957920\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042884250704\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042846525592\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042839305016\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042839305856\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042846127888\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n",
      "C:\\Users\\corylowe\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\corylowe\\AppData\\Local\\Temp\\joblib_memmaping_pool_13648_2042846664968\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each model [ 0.82807018  0.83859649  0.83464912  0.83369899  0.82580079  0.82492321\n",
      "  0.82843352  0.83150505  0.82448442  0.83669886]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83068606332027972"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(VC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each model\",scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
